{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5hAU33YWN_Sb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b3756419-0f57-49d7-974d-348d5ee65d01"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: pretty_midi in /usr/local/lib/python3.10/dist-packages (0.2.10)\n",
            "Requirement already satisfied: numpy>=1.7.0 in /usr/local/lib/python3.10/dist-packages (from pretty_midi) (1.22.4)\n",
            "Requirement already satisfied: mido>=1.1.16 in /usr/local/lib/python3.10/dist-packages (from pretty_midi) (1.2.10)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from pretty_midi) (1.16.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install pretty_midi\n",
        "import os, sys, shutil\n",
        "import time\n",
        "import json\n",
        "import math\n",
        "import argparse\n",
        "import itertools\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from tqdm import tqdm\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.tensorboard import SummaryWriter\n",
        "from torch.nn.parallel import DistributedDataParallel\n",
        "from torch.utils.data import DataLoader, Subset, DistributedSampler, Dataset\n",
        "\n",
        "from lib import constants\n",
        "from lib.model.transformer import MusicTransformer\n",
        "from lib.inverse_power_with_warmup_sheduler import InversePowerWithWarmupLRScheduler\n",
        "from lib.encoded_dataset import EncodedDataset\n",
        "from lib.augmentations import MusicAugmentations"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import zipfile\n",
        "archive = '/content/lib.zip'\n",
        "with zipfile.ZipFile(archive, 'r') as zip_file:\n",
        "    zip_file.extractall('/content')"
      ],
      "metadata": {
        "id": "uBuc_MYYxy-a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "PAD_TOKEN = constants.TOKEN_PAD\n",
        "\n",
        "params = dict(\n",
        "    NAME = 'model_name',\n",
        "    DS_FILE_PATH = 'ds_files.pt',\n",
        "    SEED = 0,\n",
        "    num_epochs = 100,\n",
        "    batch_size = 1,\n",
        "    num_workers = 0,\n",
        "    val_every = 6000,\n",
        "    save_every = 6000,\n",
        "    lr = 1e-4,\n",
        "    use_scheduler = True,\n",
        "    peak_lr = 1e-4,\n",
        "    warmup_steps = 4000,\n",
        "    power = 2,\n",
        "    shift = 100000,\n",
        "    LOAD_NAME = '',\n",
        "    LOG_TOTAL_NORM = True,\n",
        "    CLIPPING = False,\n",
        "    gpus = [0,1,2,3,4],\n",
        ")\n",
        "\n",
        "globals().update(params)\n",
        "import torch\n",
        "\n",
        "RANGE_NOTE_ON = 128\n",
        "RANGE_NOTE_OFF = 128\n",
        "RANGE_VEL = 32\n",
        "RANGE_TIME_SHIFT = 100\n",
        "\n",
        "TOKEN_END               = RANGE_NOTE_ON + RANGE_NOTE_OFF + RANGE_VEL + RANGE_TIME_SHIFT\n",
        "TOKEN_PAD               = TOKEN_END + 1\n",
        "VOCAB_SIZE              = TOKEN_PAD + 1 + 4\n",
        "\n",
        "TORCH_FLOAT             = torch.float32\n",
        "TORCH_INT               = torch.int32\n",
        "\n",
        "TORCH_LABEL_TYPE        = torch.long\n",
        "\n",
        "PREPEND_ZEROS_WIDTH     = 4\n"
      ],
      "metadata": {
        "id": "lhqKo8fTTSLT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ДАТАСЕТ\n"
      ],
      "metadata": {
        "id": "buVz5hxfYOX5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import os\n",
        "import torch\n",
        "import joblib\n",
        "import hashlib\n",
        "import pretty_midi\n",
        "import numpy as np\n",
        "from tqdm import tqdm\n",
        "from pathlib import Path\n",
        "from concurrent.futures import ProcessPoolExecutor"
      ],
      "metadata": {
        "id": "QGXFUw1ZUKh2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "DATA_DIR = '/content/drive/MyDrive/music/nsynth-valid/test_dataset'\n",
        "OUTPUT_DIR = '/content/drive/MyDrive/music/nsynth-valid/encoded_dataset'\n",
        "DS_FILE_PATH = './ds_files.pt' # сохраним сюда\n",
        "GENRES = ['classic', 'jazz', 'calm', 'pop', 'hiphop']\n",
        "MAX_LEN = 2048\n",
        "print('collecting *.mid files...')\n",
        "FILES = list(map(str, Path(DATA_DIR).rglob('*.mid')))\n",
        "DS_FILE_PATH = './ds_files.pt'\n",
        "ds_files = list(map(str, Path(OUTPUT_DIR).rglob('*.pt')))\n",
        "torch.save(ds_files, DS_FILE_PATH)\n",
        "\n",
        "print('ds_files.pt saved to', os.path.abspath(DS_FILE_PATH))"
      ],
      "metadata": {
        "id": "SFjXC-BIYLrZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f53b7e99-6c51-410f-f4d8-0d528a601729"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "collecting *.mid files...\n",
            "ds_files.pt saved to /content/ds_files.pt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pt_file = torch.load(\"/content/ds_files.pt\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Pl6elu-mgaTn",
        "outputId": "a07faa6c-2774-4484-f3f9-fed91d7d61e8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/music/nsynth-valid/encoded_dataset/pop/pop_0_3c1c5acc2d141a741dd07e570183cd93_0.pt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2UqUMK0S8cv1",
        "outputId": "eef34e9c-5169-4480-bcd2-31f2c8120e85"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def encode_fn(i):\n",
        "    '''обертка для загрузки i-го миди-файла, кодирования, заполнения и сохранения закодированного тензора на диск'''\n",
        "    file = FILES[i]\n",
        "    max_len = MAX_LEN\n",
        "    \n",
        "    path, fname = os.path.split(file)\n",
        "    try:\n",
        "            midi = pretty_midi.PrettyMIDI(file)\n",
        "            genre = path.split('/')[-1]  \n",
        "    except:\n",
        "        print(f'{i} not loaded')\n",
        "        return -1\n",
        "    print(path)\n",
        "    assert genre in GENRES, f'{genre} is not in {GENRES}'\n",
        "    \n",
        "    fname, ext = os.path.splitext(fname)\n",
        "    h = hashlib.md5(file.encode()).hexdigest()\n",
        "    save_name = f'{OUTPUT_DIR}/{genre}/{fname}_{h}'\n",
        "        \n",
        "    events = midi_processing.encode(midi, use_piano_range=True)\n",
        "    events = np.array(events)\n",
        "    split_idxs = np.cumsum([max_len]*(events.shape[0]//max_len))\n",
        "    splits = np.split(events, split_idxs, axis=0)\n",
        "    n_last = splits[-1].shape[0]\n",
        "    if n_last < 256:\n",
        "        splits.pop(-1)\n",
        "        drop_last = 1\n",
        "    else:\n",
        "        drop_last = 0\n",
        "        \n",
        "    for i, split in enumerate(splits):\n",
        "        keep_idxs = midi_processing.filter_bad_note_offs(split)\n",
        "        split = split[keep_idxs]\n",
        "        eos_idx = min(max_len - 1, len(split))\n",
        "        split = np.pad(split, [[0,max_len - len(split)]])\n",
        "        split[eos_idx] = constants.TOKEN_END\n",
        "        try:\n",
        "            torch.save(split, f'{save_name}_{i}.pt')\n",
        "        except OSError:  # если имя слишком большое\n",
        "            save_name = f'{OUTPUT_DIR}/{genre}/{h}'\n",
        "            torch.save(split, f'{save_name}_{i}.pt')\n",
        "    return drop_last"
      ],
      "metadata": {
        "id": "Eh4YV0Trg7rj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#закодируем датасет\n",
        "cpu_count = joblib.cpu_count()\n",
        "print(f'starting encoding in {cpu_count} processes...')\n",
        "x = list(tqdm(map(encode_fn, range(len(FILES))), position=0, total=len(FILES)))\n",
        "\n",
        "print('collecting encoded (*.pt) files...')\n",
        "ds_files = list(map(str, Path(OUTPUT_DIR).rglob('*.pt')))\n",
        "print('total encoded files:', len(ds_files))\n",
        "\n",
        "torch.save(ds_files, DS_FILE_PATH)\n",
        "print('ds_files.pt saved to', os.path.abspath(DS_FILE_PATH))"
      ],
      "metadata": {
        "id": "TR4rN0GyhHh_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import midi_processing"
      ],
      "metadata": {
        "id": "gohFI3CTmnRO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "from torch.utils.data import Dataset\n",
        "\n",
        "\n",
        "class EncodedDataset(Dataset):\n",
        "    \"\"\"\n",
        "    Класс набора данных для обучения и оценки модели.\n",
        "    \n",
        "    Parameters\n",
        "    ----------\n",
        "    ds_files : str\n",
        "        путь до файлаов'ds_files.pt'\n",
        "    prefix_path : str\n",
        "        prefix_path  будет добавлен в 'ds_files.pt'. Иногда используется для удобства.\n",
        "    transform : MusicAugmentations\n",
        "        трансформер\n",
        "    \"\"\"\n",
        "    def __init__(self, ds_files, prefix_path='', transform=None):\n",
        "        self.transform = transform\n",
        "        self.files = torch.load(ds_files)\n",
        "        self.prefix_path = prefix_path\n",
        "        self.genre2id = {'classic':0, 'jazz':1, 'calm':2, 'pop':3, 'hiphop':4}\n",
        "        self.genre = [self.genre2id.get(f.split('/')[1], 0) for f in self.files]\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.files)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        x = torch.load(self.prefix_path + self.files[idx])\n",
        "        if self.transform:\n",
        "            x = torch.from_numpy(self.transform(x))\n",
        "        genre = self.genre[idx]\n",
        "        return x, genre, idx"
      ],
      "metadata": {
        "id": "iDkc-eGCHE11"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# train\n"
      ],
      "metadata": {
        "id": "D12iFfTV0Tmh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def create_dataloaders(batch_size, num_workers=0):\n",
        "    '''Инициализирует дополнения, загружает списки файлов в наборы данных и загрузчики и возвращает их'''\n",
        "    print('loading data...')\n",
        "    \n",
        "    aug = MusicAugmentations()\n",
        "    \n",
        "    tr_dataset = EncodedDataset(DS_FILE_PATH, transform=aug)\n",
        "    vl_dataset = EncodedDataset(DS_FILE_PATH, transform=None)\n",
        "    \n",
        "    np.random.seed(0)\n",
        "    idxs = np.random.permutation(len(tr_dataset))\n",
        "    vl, tr = np.split(idxs, [2])\n",
        "    train_dataset = Subset(tr_dataset, tr)\n",
        "    val_dataset = Subset(vl_dataset, vl)\n",
        "    print(\"size\", len(train_dataset))\n",
        "    print(\"size\", len(val_dataset))\n",
        "    sampler = DistributedSampler(train_dataset, world_size, rank, True)\n",
        "    train_loader = DataLoader(train_dataset, batch_size=batch_size, sampler=sampler, pin_memory=False, num_workers=num_workers)\n",
        "    sampler = DistributedSampler(val_dataset, world_size, rank, False)\n",
        "    val_loader = DataLoader(val_dataset, batch_size=batch_size*4, sampler=sampler, pin_memory=False, num_workers=num_workers)\n",
        "    \n",
        "    return train_loader, val_loader"
      ],
      "metadata": {
        "id": "P4pDxQ_F0lpq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def init_model(lr, seed=0):\n",
        "    '''Инициализирует модель, при необходимости загружает веса и создает оптимизатор'''\n",
        "    torch.manual_seed(seed)\n",
        "    model = MusicTransformer(device, n_layers=12, d_model=1024, dim_feedforward=2048, num_heads=16, vocab_size=constants.VOCAB_SIZE, rpr=True).to(device)\n",
        "    if LOAD_NAME != '':\n",
        "        model.load_state_dict(torch.load(LOAD_NAME, map_location=device))\n",
        "        print(f'Loaded model from {LOAD_NAME}')\n",
        "    print(sum((torch.numel(x) for x in model.parameters()))/1e6, 'M parameters')\n",
        "    optimizer = torch.optim.AdamW(model.parameters(), lr, weight_decay=1e-5)\n",
        "    return model, optimizer"
      ],
      "metadata": {
        "id": "0-UN6cY_0syK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def validate(model, val_loader):\n",
        "    CE = 0\n",
        "    ACC = 0\n",
        "    n = 0\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        for x, genre, idxs in val_loader:\n",
        "            x[x==0] = PAD_TOKEN\n",
        "            tgt = x.clone()\n",
        "            x[:,-1] = constants.VOCAB_SIZE - 4-1 + genre\n",
        "            x = torch.roll(x, 1, -1)\n",
        "            x, tgt = x.to(device), tgt.to(device)\n",
        "\n",
        "            logits = model(x)\n",
        "            pred = logits.argmax(-1)\n",
        "\n",
        "            mask = tgt != PAD_TOKEN\n",
        "            n += mask.sum().item()\n",
        "            CE += F.cross_entropy(logits.view(-1, logits.shape[-1]), tgt.flatten(), ignore_index=PAD_TOKEN, reduction='sum').item()\n",
        "            ACC += (pred[mask] == tgt[mask]).sum().item()\n",
        "            \n",
        "    model.train()\n",
        "    return CE/n, ACC/n"
      ],
      "metadata": {
        "id": "IiNPkeAd0yJf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fworld_size = len(gpus)\n",
        "global device, NAME, SEED, rank\n",
        "rank, world_size = 0, world_size\n",
        "    \n",
        "os.environ['MASTER_ADDR'] = 'localhost'\n",
        "os.environ['MASTER_PORT'] = '12355'\n",
        "    \n",
        "device = torch.device(f'cuda:{gpus[rank]}')\n",
        "print(rank, gpus[rank], device)\n",
        "    \n",
        "train_loader, val_loader = create_dataloaders(batch_size, num_workers)\n",
        "torch.cuda.empty_cache()   \n",
        "model, optimizer = init_model(lr, SEED)\n",
        "if use_scheduler:\n",
        "  scheduler = InversePowerWithWarmupLRScheduler(optimizer, peak_lr=peak_lr, warmup_steps=warmup_steps, power=power, shift=shift)\n",
        "    \n",
        "if rank == 0:\n",
        "  save_dir = f'output/{NAME}'\n",
        "  save_name = f'{NAME}'\n",
        "  if os.path.exists(save_dir):\n",
        "    print(f'WARNING: {save_dir} exists! It may rewrite useful files')\n",
        "  os.makedirs(save_dir, exist_ok=True)\n",
        "  writer = SummaryWriter(f'runs/{save_name}')\n",
        "    \n",
        "    # TRAIN\n",
        "LS = {'loss':[], 'lr':[], 'val_ce':[], 'val_acc':[]}\n",
        "\n",
        "i_val = 0\n",
        "i_step = -1\n",
        "best_ce = float('inf')\n",
        "patience = 0\n",
        "for ep in range(num_epochs):\n",
        "        model.train()\n",
        "        train_loader.sampler.set_epoch(ep)\n",
        "        if rank == 0:\n",
        "            bar = tqdm(train_loader, position=rank)\n",
        "        else:\n",
        "            bar = train_loader\n",
        "        for x, genre, idxs in bar:\n",
        "            i_step += 1\n",
        "            x[x==0] = PAD_TOKEN\n",
        "            tgt = x.clone()\n",
        "            x[:,-1] = constants.VOCAB_SIZE - 4 - 1 + genre\n",
        "            x = torch.roll(x, 1, -1)\n",
        "            x, tgt = x.to(device), tgt.to(device)\n",
        "            torch.cuda.empty_cache()\n",
        "            logits = model(x)\n",
        "            loss = F.cross_entropy(logits.view(-1, logits.shape[-1]), tgt.flatten(), ignore_index=PAD_TOKEN)\n",
        "            \n",
        "            optimizer.zero_grad()\n",
        "            loss.backward()\n",
        "            \n",
        "            if CLIPPING:\n",
        "                total_norm = torch.nn.utils.clip_grad_norm_(model.parameters(), CLIPPING).item()\n",
        "            else:\n",
        "                total_norm = 0\n",
        "            \n",
        "            optimizer.step()\n",
        "            \n",
        "            if use_scheduler:\n",
        "                scheduler.step()\n",
        "                \n",
        "            if i_step == warmup_steps - 1 and rank == 0:\n",
        "                torch.save(model.module.state_dict(), f'{save_dir}/model_{save_name}_after_warmup.pt')\n",
        "\n",
        "            if rank == 0:\n",
        "                # logs\n",
        "                LS['loss'] += [loss.item()]\n",
        "                LS['lr'] += [optimizer.param_groups[0]['lr']]\n",
        "                writer.add_scalar(f'Train/embedding_weight_norm', torch.norm(model.embedding.weight).item(), i_step)\n",
        "                writer.add_scalar(f'Train/embedding_grad_norm', torch.norm(model.embedding.weight.grad).item(), i_step)\n",
        "                writer.add_scalar(f'Train/output_weight_norm', torch.norm(model.Wout.weight).item(), i_step)\n",
        "                writer.add_scalar(f'Train/output_grad_norm', torch.norm(model.Wout.weight.grad).item(), i_step)\n",
        "                writer.add_scalar(f'Train/loss', loss.item(), i_step)\n",
        "                writer.add_scalar(f'Train/perplexity', math.exp(loss.item()), i_step)\n",
        "                writer.add_scalar(f'Train/lr', optimizer.param_groups[0]['lr'], i_step)\n",
        "                if LOG_TOTAL_NORM:\n",
        "                    total_norm = 0.\n",
        "                    for p in model.parameters():\n",
        "                        param_norm = p.grad.detach().data.norm(2)\n",
        "                        total_norm += param_norm.item() ** 2\n",
        "                    total_norm = total_norm ** 0.5\n",
        "                    writer.add_scalar(f'Train/total_grad_norm', total_norm, i_step)\n",
        "                bar.set_postfix(loss=loss.item(), lr=optimizer.param_groups[0]['lr'], norm=total_norm)\n",
        "                \n",
        "\n",
        "            # VALIDATION\n",
        "            if i_step % val_every == val_every-1:\n",
        "                val_ce, val_acc = validate(model, val_loader)\n",
        "                if world_size > 1:\n",
        "                    ce_all, acc_all = [[torch.zeros(1,device=device) for i in range(world_size)] for _ in range(2)]\n",
        "                    [torch.distributed.all_gather(a, torch.tensor(x, dtype=torch.float32, device=device)) for a,x in zip([ce_all,acc_all], [val_ce,val_acc])]\n",
        "                    val_ce, val_acc = [torch.cat(a).mean().item() for a in [ce_all,acc_all]]\n",
        "                if rank == 0:\n",
        "                    # log, save, patience tracking\n",
        "                    LS['val_ce'] += [val_ce]\n",
        "                    LS['val_acc'] += [val_acc]\n",
        "                    writer.add_scalar(f'Val/ce', val_ce, i_val)\n",
        "                    writer.add_scalar(f'Val/acc', val_acc, i_val)\n",
        "                    writer.add_scalar(f'Val/perplexity', math.exp(val_ce), i_val)\n",
        "                    if val_ce < best_ce:\n",
        "                        patience = 0\n",
        "                        best_ce = val_ce\n",
        "                        torch.save({'history':LS,'epoch':ep,'params':params}, f'{save_dir}/hist_{save_name}_best.pt')\n",
        "                        torch.save(model.module.state_dict(), f'{save_dir}/model_{save_name}_best.pt')\n",
        "                    else:\n",
        "                        patience += 1\n",
        "                    print(f'{ep}: val_ce={val_ce}, val_acc={val_acc}, patience={patience}')\n",
        "                i_val += 1\n",
        "\n",
        "            # CHECKPOINT\n",
        "            if (i_step % save_every == save_every-1) and rank == 0:\n",
        "                torch.save({'history':LS,'epoch':ep,'params':params}, f'{save_dir}/hist_{save_name}.pt')\n",
        "                torch.save(model.module.state_dict(), f'{save_dir}/model_{save_name}_{(i_step+1)//1000}k.pt')\n",
        "    \n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Kuq-tlQKBckd",
        "outputId": "9d73ec0f-cc9c-4e18-df2c-65a3b4f9bf74"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0 0 cuda:0\n",
            "loading data...\n",
            "size 22\n",
            "size 2\n",
            "103.180682 M parameters\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 5/5 [00:07<00:00,  1.50s/it, loss=6.21, lr=1.5e-7, norm=19.6]\n",
            "100%|██████████| 5/5 [00:06<00:00,  1.31s/it, loss=6.13, lr=2.75e-7, norm=14]\n",
            "100%|██████████| 5/5 [00:06<00:00,  1.21s/it, loss=6.21, lr=4e-7, norm=11]\n",
            "100%|██████████| 5/5 [00:05<00:00,  1.18s/it, loss=6.17, lr=5.25e-7, norm=8.34]\n",
            "100%|██████████| 5/5 [00:06<00:00,  1.27s/it, loss=6.11, lr=6.5e-7, norm=8.19]\n",
            "100%|██████████| 5/5 [00:05<00:00,  1.18s/it, loss=6.16, lr=7.75e-7, norm=10.8]\n",
            "100%|██████████| 5/5 [00:05<00:00,  1.19s/it, loss=6.03, lr=9e-7, norm=9.85]\n",
            "100%|██████████| 5/5 [00:06<00:00,  1.24s/it, loss=5.97, lr=1.03e-6, norm=8.07]\n",
            "100%|██████████| 5/5 [00:05<00:00,  1.14s/it, loss=6.14, lr=1.15e-6, norm=9.05]\n",
            "100%|██████████| 5/5 [00:05<00:00,  1.17s/it, loss=6.1, lr=1.28e-6, norm=8.92]\n",
            "100%|██████████| 5/5 [00:05<00:00,  1.16s/it, loss=5.86, lr=1.4e-6, norm=8.67]\n",
            "100%|██████████| 5/5 [00:06<00:00,  1.20s/it, loss=5.89, lr=1.53e-6, norm=7.28]\n",
            "100%|██████████| 5/5 [00:05<00:00,  1.16s/it, loss=5.85, lr=1.65e-6, norm=8.6]\n",
            "100%|██████████| 5/5 [00:05<00:00,  1.15s/it, loss=5.86, lr=1.78e-6, norm=17.6]\n",
            "100%|██████████| 5/5 [00:05<00:00,  1.16s/it, loss=5.67, lr=1.9e-6, norm=7.4]\n",
            "100%|██████████| 5/5 [00:05<00:00,  1.16s/it, loss=5.84, lr=2.03e-6, norm=7.85]\n",
            "100%|██████████| 5/5 [00:05<00:00,  1.16s/it, loss=5.85, lr=2.15e-6, norm=9.72]\n",
            "100%|██████████| 5/5 [00:05<00:00,  1.17s/it, loss=5.57, lr=2.28e-6, norm=6.02]\n",
            "100%|██████████| 5/5 [00:05<00:00,  1.17s/it, loss=5.78, lr=2.4e-6, norm=18.1]\n",
            "100%|██████████| 5/5 [00:06<00:00,  1.21s/it, loss=5.6, lr=2.53e-6, norm=6.7]\n",
            "100%|██████████| 5/5 [00:05<00:00,  1.17s/it, loss=5.56, lr=2.65e-6, norm=6.87]\n",
            "100%|██████████| 5/5 [00:05<00:00,  1.18s/it, loss=5.68, lr=2.78e-6, norm=8.91]\n",
            "100%|██████████| 5/5 [00:05<00:00,  1.17s/it, loss=3.83, lr=2.9e-6, norm=46.4]\n",
            "100%|██████████| 5/5 [00:05<00:00,  1.18s/it, loss=5.64, lr=3.03e-6, norm=9.71]\n",
            "100%|██████████| 5/5 [00:05<00:00,  1.17s/it, loss=6.01, lr=3.15e-6, norm=10]\n",
            "100%|██████████| 5/5 [00:05<00:00,  1.17s/it, loss=5.56, lr=3.28e-6, norm=18]\n",
            "100%|██████████| 5/5 [00:05<00:00,  1.19s/it, loss=5.54, lr=3.4e-6, norm=7.45]\n",
            "100%|██████████| 5/5 [00:05<00:00,  1.18s/it, loss=5.55, lr=3.53e-6, norm=7.45]\n",
            "100%|██████████| 5/5 [00:05<00:00,  1.17s/it, loss=5.63, lr=3.65e-6, norm=9.81]\n",
            "100%|██████████| 5/5 [00:05<00:00,  1.17s/it, loss=3.78, lr=3.78e-6, norm=42.7]\n",
            "100%|██████████| 5/5 [00:05<00:00,  1.19s/it, loss=5.27, lr=3.9e-6, norm=6.82]\n",
            "100%|██████████| 5/5 [00:05<00:00,  1.18s/it, loss=5.53, lr=4.03e-6, norm=9.1]\n",
            "100%|██████████| 5/5 [00:06<00:00,  1.20s/it, loss=5.45, lr=4.15e-6, norm=6.35]\n",
            "100%|██████████| 5/5 [00:05<00:00,  1.19s/it, loss=5.46, lr=4.28e-6, norm=8.25]\n",
            "100%|██████████| 5/5 [00:05<00:00,  1.18s/it, loss=5.5, lr=4.4e-6, norm=11.2]\n",
            "100%|██████████| 5/5 [00:05<00:00,  1.20s/it, loss=3.02, lr=4.53e-6, norm=38.9]\n",
            "100%|██████████| 5/5 [00:05<00:00,  1.19s/it, loss=5.72, lr=4.65e-6, norm=10.6]\n",
            "100%|██████████| 5/5 [00:05<00:00,  1.20s/it, loss=5.39, lr=4.78e-6, norm=6.26]\n",
            "100%|██████████| 5/5 [00:05<00:00,  1.18s/it, loss=5.48, lr=4.9e-6, norm=14.7]\n",
            "100%|██████████| 5/5 [00:06<00:00,  1.21s/it, loss=2.51, lr=5.03e-6, norm=40.7]\n",
            "100%|██████████| 5/5 [00:05<00:00,  1.20s/it, loss=2.25, lr=5.15e-6, norm=43]\n",
            "100%|██████████| 5/5 [00:06<00:00,  1.20s/it, loss=4.02, lr=5.28e-6, norm=24.9]\n",
            "100%|██████████| 5/5 [00:06<00:00,  1.20s/it, loss=5.52, lr=5.4e-6, norm=9.33]\n",
            "100%|██████████| 5/5 [00:06<00:00,  1.20s/it, loss=5.5, lr=5.53e-6, norm=10.4]\n",
            "100%|██████████| 5/5 [00:06<00:00,  1.21s/it, loss=1.43, lr=5.65e-6, norm=25.5]\n",
            "100%|██████████| 5/5 [00:05<00:00,  1.19s/it, loss=3.75, lr=5.78e-6, norm=52.6]\n",
            "100%|██████████| 5/5 [00:06<00:00,  1.21s/it, loss=5.23, lr=5.9e-6, norm=8.17]\n",
            "100%|██████████| 5/5 [00:06<00:00,  1.23s/it, loss=5.2, lr=6.03e-6, norm=6.8]\n",
            "100%|██████████| 5/5 [00:06<00:00,  1.20s/it, loss=5.11, lr=6.15e-6, norm=18.7]\n",
            "100%|██████████| 5/5 [00:06<00:00,  1.21s/it, loss=5.34, lr=6.28e-6, norm=6.93]\n",
            "100%|██████████| 5/5 [00:05<00:00,  1.18s/it, loss=5.24, lr=6.4e-6, norm=7.28]\n",
            "100%|██████████| 5/5 [00:06<00:00,  1.21s/it, loss=3.91, lr=6.53e-6, norm=24.9]\n",
            "100%|██████████| 5/5 [00:05<00:00,  1.20s/it, loss=5.23, lr=6.65e-6, norm=14.1]\n",
            "100%|██████████| 5/5 [00:06<00:00,  1.20s/it, loss=1.66, lr=6.78e-6, norm=31.7]\n",
            "100%|██████████| 5/5 [00:05<00:00,  1.18s/it, loss=4.89, lr=6.9e-6, norm=14.8]\n",
            "100%|██████████| 5/5 [00:06<00:00,  1.20s/it, loss=5.19, lr=7.03e-6, norm=5.77]\n",
            "100%|██████████| 5/5 [00:06<00:00,  1.20s/it, loss=5.73, lr=7.15e-6, norm=8.79]\n",
            "100%|██████████| 5/5 [00:05<00:00,  1.19s/it, loss=5.01, lr=7.28e-6, norm=4.22]\n",
            "100%|██████████| 5/5 [00:05<00:00,  1.18s/it, loss=2.52, lr=7.4e-6, norm=44.9]\n",
            "100%|██████████| 5/5 [00:06<00:00,  1.20s/it, loss=1.26, lr=7.53e-6, norm=17.9]\n",
            "100%|██████████| 5/5 [00:06<00:00,  1.21s/it, loss=1.99, lr=7.65e-6, norm=29.6]\n",
            "100%|██████████| 5/5 [00:06<00:00,  1.21s/it, loss=5.18, lr=7.78e-6, norm=5.23]\n",
            "100%|██████████| 5/5 [00:06<00:00,  1.21s/it, loss=5.41, lr=7.9e-6, norm=10.2]\n",
            "100%|██████████| 5/5 [00:06<00:00,  1.21s/it, loss=3.98, lr=8.03e-6, norm=32.2]\n",
            "100%|██████████| 5/5 [00:05<00:00,  1.20s/it, loss=5.14, lr=8.15e-6, norm=6.05]\n",
            "100%|██████████| 5/5 [00:06<00:00,  1.21s/it, loss=5.21, lr=8.28e-6, norm=11.5]\n",
            "100%|██████████| 5/5 [00:06<00:00,  1.22s/it, loss=5.26, lr=8.4e-6, norm=9.53]\n",
            "100%|██████████| 5/5 [00:06<00:00,  1.22s/it, loss=1.45, lr=8.53e-6, norm=20.6]\n",
            "100%|██████████| 5/5 [00:05<00:00,  1.20s/it, loss=4.94, lr=8.65e-6, norm=4.45]\n",
            "100%|██████████| 5/5 [00:06<00:00,  1.22s/it, loss=4.94, lr=8.78e-6, norm=4.93]\n",
            "100%|██████████| 5/5 [00:05<00:00,  1.19s/it, loss=4.74, lr=8.9e-6, norm=12.4]\n",
            "100%|██████████| 5/5 [00:06<00:00,  1.21s/it, loss=4.62, lr=9.03e-6, norm=14.9]\n",
            "100%|██████████| 5/5 [00:06<00:00,  1.21s/it, loss=0.918, lr=9.15e-6, norm=4.05]\n",
            "100%|██████████| 5/5 [00:06<00:00,  1.22s/it, loss=4.9, lr=9.28e-6, norm=6.65]\n",
            "100%|██████████| 5/5 [00:06<00:00,  1.22s/it, loss=5.18, lr=9.4e-6, norm=8.66]\n",
            "100%|██████████| 5/5 [00:06<00:00,  1.22s/it, loss=0.885, lr=9.53e-6, norm=2.98]\n",
            "100%|██████████| 5/5 [00:06<00:00,  1.20s/it, loss=4.67, lr=9.65e-6, norm=12.9]\n",
            "100%|██████████| 5/5 [00:05<00:00,  1.19s/it, loss=1.08, lr=9.78e-6, norm=9.18]\n",
            "100%|██████████| 5/5 [00:06<00:00,  1.22s/it, loss=4.84, lr=9.9e-6, norm=6.78]\n",
            "100%|██████████| 5/5 [00:06<00:00,  1.21s/it, loss=4.76, lr=1e-5, norm=8.75]\n",
            "100%|██████████| 5/5 [00:06<00:00,  1.20s/it, loss=0.821, lr=1.02e-5, norm=6.05]\n",
            "100%|██████████| 5/5 [00:06<00:00,  1.22s/it, loss=4.89, lr=1.03e-5, norm=5.44]\n",
            "100%|██████████| 5/5 [00:06<00:00,  1.20s/it, loss=5.15, lr=1.04e-5, norm=7.41]\n",
            "100%|██████████| 5/5 [00:06<00:00,  1.22s/it, loss=5.04, lr=1.05e-5, norm=4.54]\n",
            "100%|██████████| 5/5 [00:06<00:00,  1.22s/it, loss=5.03, lr=1.07e-5, norm=3.92]\n",
            "100%|██████████| 5/5 [00:06<00:00,  1.21s/it, loss=5, lr=1.08e-5, norm=3.88]\n",
            "100%|██████████| 5/5 [00:06<00:00,  1.21s/it, loss=4.52, lr=1.09e-5, norm=14.7]\n",
            "100%|██████████| 5/5 [00:06<00:00,  1.21s/it, loss=4.24, lr=1.1e-5, norm=8.34]\n",
            "100%|██████████| 5/5 [00:06<00:00,  1.22s/it, loss=3.05, lr=1.12e-5, norm=12.8]\n",
            "100%|██████████| 5/5 [00:06<00:00,  1.23s/it, loss=4.95, lr=1.13e-5, norm=5.53]\n",
            "100%|██████████| 5/5 [00:06<00:00,  1.21s/it, loss=4.85, lr=1.14e-5, norm=3.34]\n",
            "100%|██████████| 5/5 [00:05<00:00,  1.19s/it, loss=5.7, lr=1.15e-5, norm=9.07]\n",
            "100%|██████████| 5/5 [00:06<00:00,  1.22s/it, loss=4.98, lr=1.17e-5, norm=4.79]\n",
            "100%|██████████| 5/5 [00:06<00:00,  1.21s/it, loss=4.79, lr=1.18e-5, norm=4.26]\n",
            "100%|██████████| 5/5 [00:06<00:00,  1.22s/it, loss=4.97, lr=1.19e-5, norm=4.62]\n",
            "100%|██████████| 5/5 [00:06<00:00,  1.20s/it, loss=4.51, lr=1.2e-5, norm=10.7]\n",
            "100%|██████████| 5/5 [00:06<00:00,  1.20s/it, loss=0.993, lr=1.22e-5, norm=2.33]\n",
            "100%|██████████| 5/5 [00:06<00:00,  1.21s/it, loss=5.07, lr=1.23e-5, norm=5.77]\n",
            "100%|██████████| 5/5 [00:06<00:00,  1.21s/it, loss=4.98, lr=1.24e-5, norm=7.23]\n",
            "100%|██████████| 5/5 [00:06<00:00,  1.22s/it, loss=0.757, lr=1.25e-5, norm=5.69]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.save(model.state_dict(), f'{save_dir}/model_{1}_{(i_step+1)//1000}k.pt')"
      ],
      "metadata": {
        "id": "at9HtWPVVB2z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "QENoWv5UOAzR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# generate"
      ],
      "metadata": {
        "id": "F0svS8keN5OU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import time\n",
        "import torch\n",
        "import argparse\n",
        "import pretty_midi\n",
        "import numpy as np\n",
        "from tqdm import tqdm\n",
        "\n",
        "from lib import constants\n",
        "from lib import midi_processing\n",
        "from lib import generation\n",
        "from lib.midi_processing import PIANO_RANGE\n",
        "from lib.model.transformer import MusicTransformer\n",
        "\n",
        "\n",
        "def decode_and_write(generated, primer, genre, out_dir='/content/output'):\n",
        "    '''Decodes event-based format to midi and writes resulting file to disk'''\n",
        "    for i, (gen, g) in enumerate(zip(generated, genre)):\n",
        "        midi = midi_processing.decode(gen)\n",
        "        midi.write(f'{out_dir}/gen_{i:>02}_{id2genre[g]}.mid')\n",
        "\n",
        "        \n",
        "id2genre = {0:'classic',1:'jazz',2:'calm',3:'pop', 4:'hiphop'}\n",
        "genre2id = dict([[x[1],x[0]] for x in id2genre.items()])\n",
        "tuned_params = {\n",
        "    0: 1.1,\n",
        "    1: 0.95,\n",
        "    2: 0.9,\n",
        "    3: 1.0,\n",
        "    4: 1.05\n",
        "}"
      ],
      "metadata": {
        "id": "5Nssxe5nuZsW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "params = {'target_seq_length': 1024, 'temperature': 1.0, 'topk': 40, 'topp': 0.99, 'topp_temperature': 1.0,\n",
        "          'at_least_k': 1, 'use_rp': False, 'rp_penalty':0.05, 'rp_restore_speed':0.7, 'seed': None}"
      ],
      "metadata": {
        "id": "6ZoUMI4eWX7z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print('loading model...')\n",
        "if torch.cuda.is_available():\n",
        "    map_location = 'cuda'\n",
        "else:\n",
        "    map_location = 'cpu'\n",
        "model = MusicTransformer(map_location, n_layers=12, d_model=1024, dim_feedforward=2048, num_heads=16, vocab_size=constants.VOCAB_SIZE, rpr=True).to(map_location).eval()\n",
        "model.load_state_dict(torch.load('/content/drive/MyDrive/music/model_1_0k.pt', map_location=map_location))\n",
        "\n",
        "    # add information about genre (first token)\n",
        "primer_genre = np.repeat([4], batch_size)\n",
        "primer = torch.tensor(primer_genre)[:,None] + constants.VOCAB_SIZE - 4 -1\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pFqtkE599cCX",
        "outputId": "7453ca48-2d93-4665-ecdf-d95ce57d0402"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loading model...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "generated = generation.generate(model, primer, **params)\n",
        "generated = generation.post_process(generated, remove_bad_generations=False)\n",
        "\n",
        "decode_and_write(generated, primer, primer_genre, '/content/')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jDrGUCQC7ZZ-",
        "outputId": "f7d70aa9-7a18-40b8-e959-24b8fba1b12d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1023/1023 [01:02<00:00, 16.39it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pm = pretty_midi.PrettyMIDI('/content/output/gen_00_hiphop.mid')"
      ],
      "metadata": {
        "id": "6Y6pTyYKGzk9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "midi_path='/content/output/gen_00_hiphop.mid'\n",
        "\n",
        "FluidSynth().midi_to_audio(midi_path, midi_path.replace('.mid', '.wav'))"
      ],
      "metadata": {
        "id": "_Bn510XtG2qD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install midi2audio\n",
        "from midi2audio import FluidSynth"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-SmSOuPaHyjr",
        "outputId": "e516a943-75d3-44f9-dc66-19a21be459cd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting midi2audio\n",
            "  Downloading midi2audio-0.1.1-py2.py3-none-any.whl (8.7 kB)\n",
            "Installing collected packages: midi2audio\n",
            "Successfully installed midi2audio-0.1.1\n"
          ]
        }
      ]
    }
  ]
}